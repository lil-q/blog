<!DOCTYPE html>
<html lang="en-us">

<head>
  <title>OpenCV-python：滤波和阈值分割 | Homeward</title>

  <meta charset="UTF-8">
  <meta name="language" content="en">
  <meta name="description" content="OpenCV-python滤波图像预处理阈值分割">
  <meta name="keywords" content="OpenCV , python , ori , Otsu">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  
  

  <link rel="shortcut icon" type="image/png" href="/favicon.ico" />

  
  
    
 
  
  
  
  
  
  
    
    <link type="text/css" rel="stylesheet" href="/css/post.min.ab05d5e01a9242c9472ee834dca8b5e136420f575e85e4d6d45b56022054489f.css" integrity="sha256-qwXV4BqSQslHLug03Ki14TZCD1deheTW1FtWAiBUSJ8="/>
  
    
    <link type="text/css" rel="stylesheet" href="/css/custom.min.56326de82df2d4841928d404adcb91e5331820b2201ba73b8a71fed24212515d.css" integrity="sha256-VjJt6C3y1IQZKNQErcuR5TMYILIgG6c7inH&#43;0kISUV0="/>
  
  
   
   
    

<script type="application/ld+json">
  
    {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/lil-q.github.io\/"
      },
      "articleSection" : "blog",
      "name" : "OpenCV-python：滤波和阈值分割",
      "headline" : "OpenCV-python：滤波和阈值分割",
      "description" : "OpenCV-python滤波图像预处理阈值分割",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "2020",
      "datePublished": "2020-02-17 14:44:55 \u002b0000 UTC",
      "dateModified" : "2020-02-17 14:44:55 \u002b0000 UTC",
      "url" : "https:\/\/lil-q.github.io\/blog\/opencv-python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C\/",
      "wordCount" : "546",
      "keywords" : ["OpenCV", "python", "ori", "Otsu", "Blog"]
    }
  
  </script>
</head>

<body>
  <div class="burger__container">
  <div class="burger" aria-controls="navigation" aria-label="Menu">
    <div class="burger__meat burger__meat--1"></div>
    <div class="burger__meat burger__meat--2"></div>
    <div class="burger__meat burger__meat--3"></div>
  </div>
</div>
 

  <nav class="nav" id="navigation">
  <ul class="nav__list">
    
    
      <li>
        <a  href="/">About</a>
      </li>
    
      <li>
        <a  class="active"
         href="/blog">技术</a>
      </li>
    
      <li>
        <a  href="/picture">相册</a>
      </li>
    
      <li>
        <a  href="/essay">随笔</a>
      </li>
    
  </ul>
</nav>


  <main>
    
    

    <div class="flex-wrapper">
      <div class="post__container">
        <div class="post">
          <header class="post__header">
            <h1 id="post__title">OpenCV-python：滤波和阈值分割</h1>
            <time datetime="2020-02-17 14:44:55 &#43;0000 UTC" class="post__date">Feb 17 2020</time> 
          </header>
          <article class="post__content">
              
<h2 id="一滤波">一、滤波<a class="anchor" href="#一滤波">#</a></h2>
<p>滤波是一种卷积操作，常用于图像的预处理。低通滤波器就是允许低频信号通过，在图像中边缘和噪点都相当于高频部分，所以低通滤波器用于去除噪点、平滑和模糊图像。高通滤波器则反之，用来增强图像边缘，进行锐化处理。</p>
<ul>
<li>低通滤波器是模糊</li>
<li>高通滤波器是锐化</li>
</ul>
<p>常见噪声有<a href="https://baike.baidu.com/item/%E6%A4%92%E7%9B%90%E5%99%AA%E5%A3%B0/3455958?fr=aladdin">椒盐噪声</a>和<a href="https://baike.baidu.com/item/%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0">高斯噪声</a>，椒盐噪声可以理解为斑点，随机出现在图像中的黑点或白点；高斯噪声可以理解为拍摄图片时由于光照等原因造成的噪声。</p>
<h3 id="11-均值滤波">1.1 均值滤波<a class="anchor" href="#11-均值滤波">#</a></h3>
<p>均值滤波是一种最简单的滤波处理，它取的是卷积核区域内元素的均值，用<code>cv2.blur()</code>实现，如3×3的卷积核：</p>
<p>$$ kernel_{m} = \frac{1}{9}\left[ \begin{matrix} 1 &amp; 1 &amp; 1 \newline 1 &amp; 1 &amp; 1 \newline 1 &amp; 1 &amp; 1 \end{matrix} \right] $$</p>
<pre><code class="language-python">img = cv2.imread('lena.jpg')
blur = cv2.blur(img, (3, 3))  # 均值模糊
</code></pre>
<h3 id="12-方框滤波">1.2 方框滤波<a class="anchor" href="#12-方框滤波">#</a></h3>
<p>方框滤波跟均值滤波很像，如3×3的滤波核如下：</p>
<p>$$ kernel_{b} = a\left[ \begin{matrix} 1 &amp; 1 &amp; 1 \newline 1 &amp; 1 &amp; 1 \newline 1 &amp; 1 &amp; 1 \end{matrix} \right] $$</p>
<p>用<code>cv2.boxFilter()</code>函数实现，当</p>
<pre><code class="language-python"># 前面的均值滤波也可以用方框滤波实现
blur = cv2.boxFilter(img, -1, (3, 3), normalize=True)
</code></pre>
<ul>
<li>参数2：<code>ddtype</code>为目标的数据类型，取-1表示和原图相同</li>
<li>可选参数<code>normalize</code>为<code>True</code>的时候，方框滤波就是均值滤波，上式中的a就等于1/9；<code>normalize</code>为<code>False</code>的时候，a=1，相当于求区域内的像素和。</li>
</ul>
<h3 id="13-高斯滤波">1.3 高斯滤波<a class="anchor" href="#13-高斯滤波">#</a></h3>
<p>前面两种滤波方式，卷积核内的每个值都一样，也就是说图像区域中每个像素的权重也就一样。高斯滤波的卷积核权重并不相同：中间像素点权重最高，越远离中心的像素权重越小。显然这种处理元素间权值的方式更加合理一些。图像是2维的，所以我们需要使用<a href="http://codec.wang/opencv-python-smoothing-images/#%E7%95%AA%E5%A4%96%E5%B0%8F%E7%AF%87%EF%BC%9A%E9%AB%98%E6%96%AF%E6%BB%A4%E6%B3%A2%E5%8D%B7%E7%A7%AF%E6%A0%B8">2维的高斯函数</a>，比如OpenCV中默认的3×3的高斯卷积核：</p>
<p>$$ kernel_{g} = \left[ \begin{matrix} 0.0625 &amp; 0.125 &amp; 0.0625 \newline 0.125 &amp; 0.25 &amp; 0.125 \newline 0.0625 &amp; 0.125 &amp; 0.0625 \end{matrix} \right] $$</p>
<p>OpenCV中对应函数为<code>cv2.GaussianBlur(src,ksize,sigmaX)</code>：</p>
<pre><code class="language-python"># 高斯滤波
gaussian = cv2.GaussianBlur(img, (5, 5), 1) 
</code></pre>
<p>参数3 σx值越大，模糊效果越明显。高斯滤波相比均值滤波效率要慢，但可以有效消除高斯噪声，能保留更多的图像细节，所以经常被称为最有用的滤波器。</p>
<h3 id="14-中值滤波">1.4 中值滤波<a class="anchor" href="#14-中值滤波">#</a></h3>
<p>中值又叫中位数，是所有数排序后取中间的值。中值滤波就是用区域内的中值来代替本像素值，所以那种孤立的斑点，如0或255很容易消除掉，适用于去除<strong>椒盐噪声</strong>和<strong>斑点噪声</strong>。中值是一种<strong>非线性操作</strong>，效率相比前面几种线性滤波要慢。</p>
<pre><code class="language-python"># 中值滤波
median = cv2.medianBlur(img, 5)  
</code></pre>
<h3 id="15-双边滤波">1.5 双边滤波<a class="anchor" href="#15-双边滤波">#</a></h3>
<p>模糊操作基本都会损失掉图像细节信息，尤其前面介绍的线性滤波器，图像的边缘信息很难保留下来。然而，边缘（edge）信息是图像中很重要的一个特征，所以这才有了另一种<strong>非线性滤波</strong>双边滤波。双边滤波在高斯滤波的基础上加入了对<strong>灰度信息的权重</strong>，即在邻域内，灰度值越接近中心点灰度值的点的权重更大，灰度值相差大的点权重越小。此权重大小，则由值域高斯函数确定。两者权重系数相乘，得到最终的卷积模板。</p>
<pre><code class="language-python"># 双边滤波
blur = cv2.bilateralFilter(img, 9, 75, 75)  
</code></pre>
<ul>
<li>参数2：d – Diameter of each pixel neighborhood that is used during filtering. If it is non-positive, it is computed from <code>sigmaSpace</code> .</li>
<li>参数3：sigmaColor – Filter sigma in the color space.</li>
<li>参数4：sigmaSpace – Filter sigma in the coordinate space.</li>
</ul>
<h3 id="16-padding">1.6 padding<a class="anchor" href="#16-padding">#</a></h3>
<p>不难发现，前面我们用3×3的核对一副6×6的图像进行卷积，得到的是4×4的图，图片缩小了！那怎么办呢？我们可以<strong>把原图扩充一圈，再卷积，这个操作叫填充padding</strong>。</p>
<p>上面的滤波函数都有一个可选参数<code>borderType</code>用来输入padding类型。</p>
<blockquote>
<p>BORDER_CONSTANT  <code>iiiiii|abcdefgh|iiiiiii</code> with some specified <code>i</code>  <br>BORDER_REPLICATE  <code>aaaaaa|abcdefgh|hhhhhhh</code>  <br>BORDER_REFLECT  <code>fedcba|abcdefgh|hgfedcb</code>  <br>BORDER_WRAP  <code>cdefgh|abcdefgh|abcdefg</code>  <br>BORDER_REFLECT_101  <code>gfedcb|abcdefgh|gfedcba</code>  <br>BORDER_TRANSPARENT  <code>uvwxyz|absdefgh|ijklmno</code>  <br>BORDER_REFLECT101  same as BORDER_REFLECT_101  <br>BORDER_DEFAULT  same as BORDER_REFLECT_101  <br>BORDER_ISOLATED  do not look outside of ROI</p>
</blockquote>
<h3 id="17-滤波总结">1.7 滤波总结<a class="anchor" href="#17-滤波总结">#</a></h3>
<ul>
<li>在不知道用什么滤波器好的时候，优先高斯滤波<code>cv2.GaussianBlur()</code>，然后均值滤波<code>cv2.blur()</code>。</li>
<li>斑点和椒盐噪声优先使用中值滤波<code>cv2.medianBlur()</code>。</li>
<li>要去除噪点的同时尽可能保留更多的边缘信息，使用双边滤波<code>cv2.bilateralFilter()</code>。</li>
<li>线性滤波方式：均值滤波、方框滤波、高斯滤波（速度相对快）。</li>
<li>非线性滤波方式：中值滤波、双边滤波（速度相对慢）。</li>
</ul>
<h2 id="二阈值分割">二、阈值分割<a class="anchor" href="#二阈值分割">#</a></h2>
<h3 id="21-固定阈值分割">2.1 固定阈值分割<a class="anchor" href="#21-固定阈值分割">#</a></h3>
<p>固定阈值分割很直接，像素点值大于阈值变成一类值，小于阈值变成另一类值。</p>
<pre><code class="language-PYTHON"># 阈值分割
ret, th = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)
</code></pre>
<p><code>cv2.threshold()</code>用来实现阈值分割，ret是return value缩写，代表当前的阈值，暂时不用理会。函数有4个参数：</p>
<ul>
<li>参数1：要处理的原图，<strong>一般是灰度图</strong></li>
<li>参数2：设定的阈值</li>
<li>参数3：最大阈值，一般为255</li>
<li>参数4：阈值的方式，主要有5种，详情：<a href="https://docs.opencv.org/4.0.0/d7/d1b/group__imgproc__misc.html#gaa9e58d2860d4afa658ef70a9b1115576">ThresholdTypes</a></li>
</ul>
<p><img src="https://qttblog.oss-cn-hangzhou.aliyuncs.com/opencv/threshold.png" alt=""></p>
<p>最常见的就是前两种，相当于二值化。</p>
<h3 id="22-自适应阈值">2.2 自适应阈值<a class="anchor" href="#22-自适应阈值">#</a></h3>
<p>看得出来固定阈值是在整幅图片上应用一个阈值进行分割，<strong>它并不适用于明暗分布不均的图片</strong>。 <code>cv2.adaptiveThreshold()</code>自适应阈值会每次取图片的一小部分计算阈值，这样图片不同区域的阈值就不尽相同。</p>
<pre><code class="language-python">import matplotlib.pyplot as plt
import cv2

# 自适应阈值对比固定阈值
img = cv2.imread('img_name.jpg', 0)

# 固定阈值
ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)
# 自适应阈值
th2 = cv2.adaptiveThreshold(
    img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 4)
th3 = cv2.adaptiveThreshold(
    img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 17, 6)

titles = ['Original', 'Global(v = 127)', 'Adaptive Mean', 'Adaptive Gaussian']
images = [img, th1, th2, th3]

for i in range(4):
    plt.subplot(2, 2, i + 1), plt.imshow(images[i], 'gray')
    plt.title(titles[i], fontsize=8)
    plt.xticks([]), plt.yticks([])
plt.show()
</code></pre>
<ul>
<li>参数1：要处理的原图</li>
<li>参数2：最大阈值，一般为255</li>
<li>参数3：小区域阈值的计算方式
<ul>
<li><code>ADAPTIVE_THRESH_MEAN_C</code>：小区域内取均值</li>
<li><code>ADAPTIVE_THRESH_GAUSSIAN_C</code>：小区域内加权求和，权重是个高斯核</li>
</ul>
</li>
<li>参数4：阈值方式（跟前面讲的那5种相同）</li>
<li>参数5：小区域的面积，如11就是11*11的小块</li>
<li>参数6：最终阈值等于小区域计算出的阈值再减去此值</li>
</ul>
<h3 id="23-otsu阈值法">2.3 Otsu阈值法<a class="anchor" href="#23-otsu阈值法">#</a></h3>
<pre><code class="language-python"># 先进行高斯滤波，再使用Otsu阈值法
blur = cv2.GaussianBlur(img, (5, 5), 0)
ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
</code></pre>
<p>$$ g=\omega_0\omega_1(\mu_0-\mu_1)^2 $$</p>
<p>g 就是前景与背景两类之间的方差，这个值越大，说明<strong>前景和背景的差别也就越大，效果越好。Otsu算法便是遍历阈值T，使得 g 最大，所以又称为最大类间方差法</strong>。基本上双峰图片的阈值T在两峰之间的谷底。<a href="http://codec.wang/opencv-python-extra-otsu-thresholding/">原文地址</a></p>
<h3 id="24-背景差分">2.4 背景差分<a class="anchor" href="#24-背景差分">#</a></h3>
<p>背景差分（Background Subtraction, BS）是通过使用<strong>静态</strong>相机来生成前景蒙版（即包含属于场景中的<strong>移动对象</strong>的像素的二进制图像）的通用且广泛使用的技术。 顾名思义，BS是在当前帧和背景模型之间执行减法运算，其中场景的静态部分，或者可视为背景的所有内容将被减去，移动对象将会被提取出来。如下图所示。</p>
<p><img src="https://qttblog.oss-cn-hangzhou.aliyuncs.com/opencv/Background_Subtraction_Tutorial_Scheme.png" alt=""></p>
<p>后台建模包括两个主要步骤：</p>
<ul>
<li>背景初始化</li>
<li>当前帧更新</li>
</ul>
<p>官方给出了下面的例子：</p>
<pre><code class="language-python">from __future__ import print_function
import cv2 as cv
import argparse

parser = argparse.ArgumentParser(description='This program shows how to use background subtraction methods provided by OpenCV. You can process both videos and images.')
parser.add_argument('--input', type=str, help='Path to a video or a sequence of image.', default='Video_name.mp4') # 输入视频路径
parser.add_argument('--algo', type=str, help='Background subtraction method (KNN, MOG2).', default='KNN') # 输入差分方法: KNN or MOG2
args = parser.parse_args()

## [create]
#create Background Subtractor objects
if args.algo == 'MOG2':
    backSub = cv.createBackgroundSubtractorMOG2()
else:
    backSub = cv.createBackgroundSubtractorKNN()
## [create]

## [capture]
capture = cv.VideoCapture(cv.samples.findFileOrKeep(args.input))
if not capture.isOpened:
    print('Unable to open: ' + args.input)
    exit(0)
## [capture]

while True:
    ret, frame = capture.read()
    if frame is None:
        break

    ## [apply]
    #update the background model
    fgMask = backSub.apply(frame)
    ## [apply]

    ## [display_frame_number]
    #get the frame number and write it on the current frame
    cv.rectangle(frame, (10, 2), (100,20), (255,255,255), -1)
    cv.putText(frame, str(capture.get(cv.CAP_PROP_POS_FRAMES)), (15, 15),
               cv.FONT_HERSHEY_SIMPLEX, 0.5 , (0,0,0))
    ## [display_frame_number]

    ## [show]
    #show the current frame and the fg masks
    cv.imshow('Frame', frame)
    cv.imshow('FG Mask', fgMask)
    ## [show]

    keyboard = cv.waitKey(30)
    if keyboard == ord('q') or keyboard == 27:
        break
</code></pre>
<p>关于KNN，MOG2，GMG的区别之后再补充。移动的哆啦A梦如图</p>
<p><img src="https://qttblog.oss-cn-hangzhou.aliyuncs.com/opencv/114759.png" alt=""></p>
<h2 id="参考">参考<a class="anchor" href="#参考">#</a></h2>
<ol>
<li><a href="https://github.com/ex2tron/OpenCV-Python-Tutorial/tree/master">ex2tron</a></li>
<li><a href="http://codec.wang/opencv-python-smoothing-images/#%E7%9B%AE%E6%A0%87">codec.wang</a></li>
<li><a href="https://docs.opencv.org/4.2.0/d1/dc5/tutorial_background_subtraction.html">OpenCV tutorial</a></li>
</ol>


              
                  

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
            showMathMenu: false, //disables context menu
            tex2jax: {
            inlineMath: [ ['$','$'], ['\\(','\\)'] ]
           }
    });
</script>
              
          </article>
          

<ul class="tags__list">
    
    <li class="tag__item">
        <a class="tag__link" href="https://lil-q.github.io/tags/opencv/">opencv</a>
    </li></ul>

 <div class="pagination">
  
    <a class="pagination__item" href="https://lil-q.github.io/blog/opencv-python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
        <span class="pagination__label">Previous Post</span>
        <span class="pagination__title">OpenCV-python：基础</span>
    </a>
  

  
    <a class="pagination__item" href="https://lil-q.github.io/blog/opencv-python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%89/">
      <span class="pagination__label">Next Post</span>
      <span class="pagination__title" >OpenCV-python：图像混合与形态学</a>
    </a>
  
</div>

          
          <footer class="post__footer">
            


<div class="social-icons">
  
     
    
  
     
    
      <a class="social-icons__link" title="GitHub"
         href="https://github.com/lil-q"
         target="_blank" rel="noopener">
        <div class="social-icons__icon" style="background-image: url('https://lil-q.github.io/svg/github.svg')"></div>
      </a>
    
  
     
    
      <a class="social-icons__link" title="Email"
         href="mailto:qitiantianc137@outlook.com"
         target="_blank" rel="noopener">
        <div class="social-icons__icon" style="background-image: url('https://lil-q.github.io/svg/email.svg')"></div>
      </a>
    
     
</div>

            <p>2020 © lil-q</p>
          </footer>
          </div>
      </div>
      
      <div class="toc-container">
          
        <nav id="TableOfContents">
  <ul>
    <li><a href="#一滤波">一、滤波</a>
      <ul>
        <li><a href="#11-均值滤波">1.1 均值滤波</a></li>
        <li><a href="#12-方框滤波">1.2 方框滤波</a></li>
        <li><a href="#13-高斯滤波">1.3 高斯滤波</a></li>
        <li><a href="#14-中值滤波">1.4 中值滤波</a></li>
        <li><a href="#15-双边滤波">1.5 双边滤波</a></li>
        <li><a href="#16-padding">1.6 padding</a></li>
        <li><a href="#17-滤波总结">1.7 滤波总结</a></li>
      </ul>
    </li>
    <li><a href="#二阈值分割">二、阈值分割</a>
      <ul>
        <li><a href="#21-固定阈值分割">2.1 固定阈值分割</a></li>
        <li><a href="#22-自适应阈值">2.2 自适应阈值</a></li>
        <li><a href="#23-otsu阈值法">2.3 Otsu阈值法</a></li>
        <li><a href="#24-背景差分">2.4 背景差分</a></li>
      </ul>
    </li>
    <li><a href="#参考">参考</a></li>
  </ul>
</nav>
      </div>
      
    </div>
    

  </main>

   

  
  <script src="/js/index.min.49e4d8a384357d9b445b87371863419937ede9fa77737522ffb633073aebfa44.js" integrity="sha256-SeTYo4Q1fZtEW4c3GGNBmTft6fp3c3Ui/7YzBzrr&#43;kQ=" crossorigin="anonymous"></script>
  
  
  <script src="https://unpkg.com/prismjs@1.20.0/components/prism-core.min.js"></script>

  
  <script src="https://unpkg.com/prismjs@1.20.0/plugins/autoloader/prism-autoloader.min.js"
    data-autoloader-path="https://unpkg.com/prismjs@1.20.0/components/"></script>

  
    <script src="/js/table-of-contents.js"></script>
  


</body>

</html>
